{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from utils import add_api_key\n",
    "add_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from models.tools import DBSearchTool\n",
    "from models.llm.agent.custom_streming_callback import CustomStreamingStdOutCallbackHandler\n",
    "from models.llm.chain import InstantlyAnswerableDiscriminatorChain, PlanningChain\n",
    "\n",
    "class ChatAgentModule:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.tools = [DBSearchTool()]\n",
    "        self.instantly_answerable_discriminator = InstantlyAnswerableDiscriminatorChain(verbose=verbose)\n",
    "        self.planning_chain = PlanningChain(tools=self.tools, verbose=verbose, model='gpt-4-1106-preview')\n",
    "    \n",
    "    def run(self, query, chat_history: List[List[str]]=[], project_id=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (str): 사용자 입력\n",
    "            chat_history (List[List[str]]): [[사용자 입력, 챗봇 출력], ...]\n",
    "        \"\"\"\n",
    "        self.queue = [] # TODO: 나중에 backend에서 주면 삭제\n",
    "        self.streaming_callback = CustomStreamingStdOutCallbackHandler(queue=self.queue)\n",
    "        result = self.instantly_answerable_discriminator.run(query=query, chat_history=chat_history)\n",
    "        print(f'Instantly answerable: {result}')\n",
    "        if result['instantly answerable'] == 'yes':\n",
    "            return result['answer']\n",
    "        else:\n",
    "            file_name_text = self.tools[0].get_summary_by_project_id(project_id)\n",
    "            result = self.planning_chain.run(query=query, database_filename=file_name_text, chat_history=chat_history)\n",
    "            print(f'Planning result: {result}')\n",
    "            plan_list = list(result[key] for key in result.keys() if 'step' in key)\n",
    "            return plan_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n",
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n"
     ]
    }
   ],
   "source": [
    "chat_agent = ChatAgentModule(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a GPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\n",
      "\n",
      "As my esteemed AI language assistant, you are tasked with determining whether my input can be answered or not. \n",
      "\n",
      "If you can answer, then you should providing me the most efficient and accurate solutions to my queries.\n",
      "\n",
      "By diligently analyzing my inputs, you must swiftly identify my intent and tailor your responses accordingly.\n",
      "\n",
      "## RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you can instantly answer the input.\n",
      "```json\n",
      "{\n",
      "    \"instantly answerable\": \"yes\",\n",
      "    \"reason\": string \\ reason for why you can instantly answer the input,\n",
      "    \"answer\": string \\ Answer for my input. Always respond in a very natural Korean language. Tone and manner should be friendly. \n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you can not instantly answer the input.\n",
      "```json\n",
      "{\n",
      "    \"instantly answerable\": \"no\",\n",
      "    \"reason\": string \\ reason for why you can not instantly answer the input,\n",
      "}\n",
      "```\n",
      "\n",
      "Human: 전기차 시장의 2020년과 2021년 규모를 비교해줘\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Instantly answerable: {'instantly answerable': 'no', 'reason': 'I am unable to instantly provide the comparison of the size of the electric car market in 2020 and 2021 as it requires up-to-date market research data and analysis.', 'language': 'ko'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your role is to create a plan for solving my problem.\n",
      "\n",
      "First understand the problem, extract relevant variables and their corresponding numerals, and devise a plan.\n",
      "\n",
      "Let's think step by step.\n",
      "\n",
      "## TOOLS\n",
      "-------------\n",
      "You can include the following tools in your plan \n",
      "\n",
      "### Database Search\n",
      "You can search the database. Here's a summary of the information inside the database. \n",
      "===\n",
      "file 1: 올해 전기차와 하이브리드차의 규모가 예상보다 100만대 이상 감소하고 성장률도 하향조정됐다. 전기차 시장의 성장 둔화는 경기침체와 보조금 감축 등의 영향으로 소비자들의 부담이 커졌기 때문이다. 반면 하이브리드차의 비중은 예상보다 더 커지고, 전기차의 비중은 낮아질 것으로 전망된다.\n",
      "===\n",
      "You can get more information by call this tool with query.\n",
      "\n",
      "\n",
      "## RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "When responding to me, please output a response in below format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"analyze problem\": string \\ Analyze problem based on my intent\n",
      "    \"step 1\": string \\ Step 1 of the plan\n",
      "    \"step 2\": string \\ Step 2 of the plan\n",
      "    ...\n",
      "}\n",
      "```\n",
      "\n",
      "Human: 전기차 시장의 2020년과 2021년 규모를 비교해줘\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Planning result: {'analyze problem': 'To compare the size of the electric vehicle (EV) market between 2020 and 2021, we need to obtain market size data for both years. Relevant variables would include the number of EVs sold, market share, and possibly growth rate or other indicators.', 'step 1': 'Use the Database Search tool to find the market size data for EVs in the year 2020.', 'step 2': 'Use the Database Search tool to find the market size data for EVs in the year 2021.', 'step 3': 'Compare the relevant figures from both years to identify any growth or decline in the market size.', 'step 4': 'Analyze and present the comparison data to find trends or significant changes between the two years.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Use the Database Search tool to find the market size data for EVs in the year 2020.',\n",
       " 'Use the Database Search tool to find the market size data for EVs in the year 2021.',\n",
       " 'Compare the relevant figures from both years to identify any growth or decline in the market size.',\n",
       " 'Analyze and present the comparison data to find trends or significant changes between the two years.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(query='전기차 시장의 2020년과 2021년 규모를 비교해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm.chain import DBToolQueryGeneratorChain, PlanAnswerChain, PlanAnswerCriticChain, NewPlanningChain\n",
    "\n",
    "class PlanExecutor:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.tools = [DBSearchTool()]\n",
    "        self.instantly_answerable_discriminator = InstantlyAnswerableDiscriminatorChain(verbose=verbose)\n",
    "        self.db_tool_query_generator = DBToolQueryGeneratorChain(verbose=verbose)\n",
    "        self.plan_answer_chain = PlanAnswerChain(verbose=verbose, model='gpt-4-1106-preview')\n",
    "        self.plan_answer_critic_chain = PlanAnswerCriticChain(verbose=verbose)\n",
    "        self.new_planning_chain = NewPlanningChain(verbose=verbose)\n",
    "        self.tool_dict = self.create_tool_dict(self.tools)\n",
    "    \n",
    "    def run(self, plan, project_id=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (str): 사용자 입력\n",
    "            chat_history (List[List[str]]): [[사용자 입력, 챗봇 출력], ...]\n",
    "        \"\"\"\n",
    "        result = self.instantly_answerable_discriminator.run(query=plan, chat_history=[])\n",
    "        if result['instantly answerable'] == 'yes':\n",
    "            return result['answer']\n",
    "        else:\n",
    "            result = self.db_tool_query_generator.run(query=plan)\n",
    "            search_result = self.execute_tool('Database Search', result['query'])\n",
    "            plan_answer = self.plan_answer_chain.run(query=plan, context=search_result)\n",
    "            critic_result = self.plan_answer_critic_chain.run(query=plan, answer=plan_answer['final answer'])\n",
    "            if critic_result['success'] == 'yes':\n",
    "                return plan_answer['final answer']\n",
    "            elif (critic_result['success'] == 'no') or (critic_result['success'] == 'partly'):\n",
    "                answer = critic_result.get('answer', None)\n",
    "                feedback = critic_result['feedback']\n",
    "                plan = self.new_planning_chain.run(previous_command=plan, feedback=feedback)\n",
    "                print(plan)\n",
    "\n",
    "    def execute_tool(self, tool_name, tool_input):\n",
    "        if tool_name in self.tool_dict:\n",
    "            return self.tool_dict[tool_name].run(tool_input)\n",
    "        \n",
    "    def create_tool_dict(self, tools):\n",
    "        return {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n",
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n",
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n",
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n",
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n"
     ]
    }
   ],
   "source": [
    "plan_executor = PlanExecutor(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a GPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\n",
      "\n",
      "As my esteemed AI language assistant, you are tasked with determining whether my input can be answered or not. \n",
      "\n",
      "If you can answer, then you should providing me the most efficient and accurate solutions to my queries.\n",
      "\n",
      "By diligently analyzing my inputs, you must swiftly identify my intent and tailor your responses accordingly.\n",
      "\n",
      "## RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "When responding to me, please output a response in one of two formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if you can instantly answer the input.\n",
      "```json\n",
      "{\n",
      "    \"instantly answerable\": \"yes\",\n",
      "    \"reason\": string \\ reason for why you can instantly answer the input,\n",
      "    \"answer\": string \\ Answer for my input. Always respond in a very natural Korean language. Tone and manner should be friendly. \n",
      "}\n",
      "```\n",
      "\n",
      "**Option #2:**\n",
      "Use this if you can not instantly answer the input.\n",
      "```json\n",
      "{\n",
      "    \"instantly answerable\": \"no\",\n",
      "    \"reason\": string \\ reason for why you can not instantly answer the input,\n",
      "}\n",
      "```\n",
      "\n",
      "Human: Use the Database Search tool to find the market size data for EVs in the year 2020.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are an assistant who generates queries for search. Generate a search query for the input.\n",
      "\n",
      "Ouput format:\n",
      "```json\n",
      "{\n",
      "    \"query\": string\n",
      "}\n",
      "```\n",
      "\n",
      "Human: Use the Database Search tool to find the market size data for EVs in the year 2020.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "Given the following extracted parts of a document and a question, create a final answer. \n",
      "Provide a rich answer that maximizes the use of relevant content.\n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "\n",
      "Ouput format:\n",
      "```json\n",
      "{\n",
      "    \"final answer\": string\n",
      "}\n",
      "```\n",
      "\n",
      "Human: \n",
      "Question: Use the Database Search tool to find the market size data for EVs in the year 2020.\n",
      "Document:\n",
      "------\n",
      "result1. 한겨레광고본문경제자동차‘전기차 시장’ 성장 더뎌졌다…하이브리드는 되레 선전전기차 성장 둔화, 경기침체·보조금 감축 등 영향기자최우리2023-11-16 14:472023-11-16 14:47SNE리서치 제공올해 세계 80개국에 등록된 전기차와 하이브리드차의 규모가 약 1377만대가 될 것이라는 전망이 나왔다. 상반기에 예측했던 대수보다 100만대 이상 감소했다. 성장률도 36.4%에서 30.6%로 하향조정됐다. 업계에서는 성장률 둔화가 내년까지 지속할 것으로 본다.\n",
      "\n",
      "\n",
      "result2. 시장조사기관 에스엔이(SNE)리서치는 16일 이같은 전망치를 내놓으면서 내년에도 성장률이 20% 전후로 전보다 더딘 성장을 보일 것이라고 밝혔다. 전기차 시장 성장 둔화는 경기침체로 인해 소비자들이 비싼 전기차 가격에 부담이 커졌고, 보조금 감축과 충전 인프라 부족 문제 등이 맞물리면서 소비 심리가 위축되었기 때문이다. 또 코로나19 기간 자동차 공급난으로 인한 대기 수요가 몰린 효과가 올해 들어 약해지면서 성장률을 둔화시켰다고 에스엔이리서치는 분�이리서치는 분석했다.반면 하이브리드차(HEV)의 비중은 기존 전망 보다 더 커질 것으로 보인다. 당초 전기차(49%)-하이브리드차(32%)-플러그인하이브리드차(19%)로 판매 비중을 예측했지만, 하이브리드차는 36%로 높아지는 대신 전기차는 45%로 떨어질 것으로 전망했다. 에스엔이리서치는 “보조금 감축과 폐지로 인해 중국에서 순수 전기차 비중이 감소하고 유럽 지역에서 하이브리드차 비중이 증가한 것으로 보인다. 전 지역에 걸쳐 기존 예상보다 하이브리드차가 감소하지 않은 것으로 감소하지 않은 것으로 분석됐다”고 짚었다.광고순수 전기차, 하이브리드차, 플러그인하이브리드 비중 비교. SNE리서치 제공 ※ 이미지를 누르면 크게 볼 수 있습니다.최우리 기자ecowoori@hani.co.kr전기차전기차하이브리드최우리기자다른 기사 어떠세요기아·한국GM 최대 실적…완성차 5사 799만대 판매 달성현대차, 광명 전기차 공장서 신년회…정의선 “지속가능한 미래 열어야”권력에 타협하지 않는 언론,\n",
      "\n",
      "\n",
      "result3. 이 기사 어떻게 생각하시나요?좋아요0슬퍼요0화나요0감동했어요0응원해요0전기차기사491현대차, 광명 전기차 공장서 신년회…정의선 “지속가능한 미래 열어야”한풀 꺾인 전기차, 치고 오르는 하이브리드…차세대 승자는 누구?전기차 늘며 숙제 된 배터리 재활용…중국산 처리가 관건한겨레 사설 중에서설사 성사가 되지 않더라도 1400만명이 넘는 개인 투자자의 표를 노려보겠다는 전형적인 매표 전략이다.[사설] 대통령 금투세 폐지 주장, 총선 겨냥 퇴행적 포퓰리즘뉴스룸 PICK600만명 데이터 9년치 학습한 AI, 수명 예측 78% 적중했다 [곽노필의 미래창]교실 문턱 못 넘는 우리 아이…걱정 마세요, 분리불안은 반드시 낫습니다빌 게이츠 조언 구한 DJ, 세계가 놀란 초고속인터넷 깔다광고#덕분에, 더 따뜻한 세상이웃에 약초·버섯 나누던 59살 아빠...3명 살리고 떠나“누가 눈 치웠지?”…무인매장 앞 CCTV에 찍힌 어르신\n",
      "\n",
      "\n",
      "\n",
      "------\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your role is an assistant to determine if the question was answered correctly. \n",
      "\n",
      "## RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "When responding to me, please output a response in one of three formats:\n",
      "\n",
      "**Option 1:**\n",
      "Use this if the question was answered correctly. \n",
      "```json\n",
      "{\n",
      "    \"success\": \"yes\",\n",
      "    \"answer\": string \\ answer to the question,\n",
      "}\n",
      "```\n",
      "\n",
      "**Option 2:**\n",
      "Use this if the question was answered partly correctly.\n",
      "```json\n",
      "{\n",
      "    \"success\": \"partly\",\n",
      "    \"answer\": string \\ The part of the answer given that is relevant to the question,\n",
      "    \"feedback\": string \\ What needs to be supplemented to fulfill the question\n",
      "}\n",
      "```\n",
      "\n",
      "**Option 3:**\n",
      "Use this if the answer given in the question is incorrect.\n",
      "```json\n",
      "{\n",
      "    \"success\": \"no\",\n",
      "    \"feedback\": string \\ What needs to be supplemented to fulfill the question\n",
      "}\n",
      "```\n",
      "\n",
      "Human: \n",
      "Question: Use the Database Search tool to find the market size data for EVs in the year 2020.\n",
      "Answer: The document provided does not contain the specific market size data for EVs in the year 2020. It discusses projections and growth rates for electric and hybrid vehicles in a future year, along with factors affecting the EV market, but does not give historical data for 2020.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your role is to modify the previous command in response to the feedback.\n",
      "\n",
      "## RESPONSE FORMAT INSTRUCTIONS\n",
      "----------------------------\n",
      "When responding to me, please output a response in below format:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"thought\": string \\ Thought about how to modify commands in response to feedback\n",
      "    \"new command\": string \\ Commands revised based on feedback\n",
      "}\n",
      "```\n",
      "\n",
      "Human: \n",
      "Previous command: Use the Database Search tool to find the market size data for EVs in the year 2020.\n",
      "Feedback: The answer does not fulfill the question. Please provide the specific market size data for EVs in the year 2020 using the Database Search tool.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'thought': 'I need to be more specific and focus solely on providing the market size data for EVs in the year 2020.', 'new command': 'Use the Database Search tool to specifically find the market size data for electric vehicles in the year 2020.'}\n"
     ]
    }
   ],
   "source": [
    "plan_executor.run(plan='Use the Database Search tool to find the market size data for EVs in the year 2020.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n",
      "WARNING! response_format is not default parameter.\n",
      "                    response_format was transferred to model_kwargs.\n",
      "                    Please confirm that response_format is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from modules.file_to_db.file_processor import FileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한겨레 광고 본문 경제 자동차 ‘전기차 시장’ 성장 더뎌졌다…하이브리드는 되레 선전 전기차 성장 둔화, 경기침체·보조금 감축 등 영향 기자 최우리 2023-11-16 14:47 2023-11-16 14:47 SNE리서치 제공 올해 세계 80개국에 등록된 전기차와 하이브리드차의 규모가 약 1377만대가 될 것이라는 전망이 나왔다. 상반기에 예측했던 대수보다 100만대 이상 감소했다. 성장률도 36.4%에서 30.6%로 하향조정됐다. 업계에서는 성장률 둔화가 내년까지 지속할 것으로 본다. 시장조사기관 에스엔이(SNE)리서치는 16일 이같은 전망치를 내놓으면서 내년에도 성장률이 20% 전후로 전보다 더딘 성장을 보일 것이라고 밝혔다. 전기차 시장 성장 둔화는 경기침체로 인해 소비자들이 비싼 전기차 가격에 부담이 커졌고, 보조금 감축과 충전 인프라 부족 문제 등이 맞물리면서 소비 심리가 위축되었기 때문이다. 또 코로나19 기간 자동차 공급난으로 인한 대기 수요가 몰린 효과가 올해 들어 약해지면서 성장률을 둔화시켰다고 에스엔이리서치는 분석했다. 반면 하이브리드차(HEV)의 비중은 기존 전망 보다 더 커질 것으로 보인다. 당초 전기차(49%)-하이브리드차(32%)-플러그인하이브리드차(19%)로 판매 비중을 예측했지만, 하이브리드차는 36%로 높아지는 대신 전기차는 45%로 떨어질 것으로 전망했다. 에스엔이리서치는 “보조금 감축과 폐지로 인해 중국에서 순수 전기차 비중이 감소하고 유럽 지역에서 하이브리드차 비중이 증가한 것으로 보인다. 전 지역에 걸쳐 기존 예상보다 하이브리드차가 감소하지 않은 것으로 분석됐다”고 짚었다. 광고 순수 전기차, 하이브리드차, 플러그인하이브리드 비중 비교. SNE리서치 제공 ※ 이미지를 누르면 크게 볼 수 있습니다. 최우리 기자 ecowoori@hani.co.kr 전기차 전기차 하이브리드 최우리기자 다른 기사 어떠세요 기아·한국GM 최대 실적…완성차 5사 799만대 판매 달성 현대차, 광명 전기차 공장서 신년회…정의선 “지속가능한 미래 열어야” 권력에 타협하지 않는 언론, 이 기사 어떻게 생각하시나요? 좋아요 0 슬퍼요 0 화나요 0 감동했어요 0 응원해요 0 전기차 기사491 현대차, 광명 전기차 공장서 신년회…정의선 “지속가능한 미래 열어야” 한풀 꺾인 전기차, 치고 오르는 하이브리드…차세대 승자는 누구? 전기차 늘며 숙제 된 배터리 재활용…중국산 처리가 관건 한겨레 사설 중에서 설사 성사가 되지 않더라도 1400만명이 넘는 개인 투자자의 표를 노려보겠다는 전형적인 매표 전략이다. [사설] 대통령 금투세 폐지 주장, 총선 겨냥 퇴행적 포퓰리즘 뉴스룸 PICK 600만명 데이터 9년치 학습한 AI, 수명 예측 78% 적중했다 [곽노필의 미래창] 교실 문턱 못 넘는 우리 아이…걱정 마세요, 분리불안은 반드시 낫습니다 빌 게이츠 조언 구한 DJ, 세계가 놀란 초고속인터넷 깔다 광고 #덕분에, 더 따뜻한 세상 이웃에 약초·버섯 나누던 59살 아빠...3명 살리고 떠나 “누가 눈 치웠지?”…무인매장 앞 CCTV에 찍힌 어르신 ‘90원 아침밥’ 할머니가 남긴 사랑…“산골 아이들 배 든든하게” #2023 현장 그 후 농지 돌아가는 잼버리 야영지…주민들 마음엔 상처만 남았다 폭우에 부서진 집 그대로…임시주택 떠날 2년 뒤 더 걱정 전세사기 그 후…집은 엉망, 가해자는 발뺌, 정부도 미적대 #22대 총선 ‘사진 따귀’ 노인회장, 한동훈 손 맞잡고 “국힘엔 희망 있겠다” 한동훈, 인재영입위원장 겸임…이철규와 공동위원장 체제로 허은아 “국힘 인테리어 바꿔도 본질 안 바뀌어”…이준석 신당으로 [영상] #이스라엘-하마스 전쟁 레바논서 하마스 핵심 암살한 이스라엘, 가자전쟁 확전 노렸나 튀르키예 “이스라엘 스파이” 34명 체포…팔레스타인인 감시·납치 등 혐의 후티 반군 공격, 위태로운 홍해…유엔 안보리 긴급 소집될 듯 이전 다음 댓글 광고 오늘의 주요기사 한동훈, 인재영입위원장 겸임…이철규와 공동위원장 체제 1월 4일 한겨레 그림판 태영건설에 시장 떠는 이유…3개월 만기 ‘ABCP’ 뭐길래 정치인 피습에 근거 없는 ‘자작극’ 논란…선거법 처벌은 어려워 ‘강진’ 일본 원전 물 넘치고, 기름도 새...외부 유출은 없는 듯 ‘노동자 감전사’ 철강업체 대표 재판행…중대재해법 위반 혐의 북 김여정 “무식한 윤석열…문재인은 다루기 까다로웠다” 7900개 배달업체 난립…‘대행사 등록제’ ‘라이더 자격증’ 요구 다음 광고 많이 본 기사 1 ‘이재명 피습’ 범인은 부동산중개업 60대…경찰 “살인미수 적용” 2 ‘피습’ 이재명, 서울대병원 이송…“경정맥 손상 의심” 3 일본도 놀란 동해 대지진…압력밥솥 터지듯 고온·고압 바닷물 분출 4 북 김여정 “윤석열 무식…문재인은 다루기 까다로워” 5 새해 전날 숨진 111살 할아버지, 끼니마다 와인 곁들였다 6 “남성 역차별 확신했는데, 알고 보니 여성혐오가 우리 일상” 7 이재명에 “사인 해달라” 접근한 뒤 흉기 공격 8 윤 대통령 “패거리 카르텔”, 검찰이 떠오른 이유 9 삼성반도체 평택공장 건설노동자 7m 높이 추락사 10 법원, 이재명 습격 피의자 집·사무실 압수수색 영장 발부 회사소개 구독신청 광고안내 채용 고충처리 고객센터 저작권 회원약관 개인정보취급방침 지적재산보호정책 이메일주소 무단수집거부 홈 Copyright © The Hankyoreh. All rights reserved.\n",
      "올해 전기차와 하이브리드차의 규모가 예상보다 100만대 이상 감소하고 성장률도 하향조정됐다. 전기차 시장의 성장 둔화는 경기침체와 보조금 감축 등의 영향으로 소비자들의 부담이 커졌기 때문이다. 반면 하이브리드차의 비중은 예상보다 더 커지고, 전기차의 비중은 낮아질 것으로 전망된다.\n"
     ]
    }
   ],
   "source": [
    "file_processor = FileProcessor()\n",
    "file_processor('https://www.hani.co.kr/arti/economy/car/1116579.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refeat_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
